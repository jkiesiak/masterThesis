{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import json\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.feature import StopWordsRemover, Word2Vec, RegexTokenizer, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-JNLB3CB:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2302bb95070>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "class StreamingThread(Thread):\n",
    "    def __init__(self, ssc):\n",
    "        Thread.__init__(self)\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)\n",
    "\n",
    "sc\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- tweet_id: long (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('..\\\\data\\\\dump.json')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+--------------------+\n",
      "|         label|           tweet_id|          tweet_text|\n",
      "+--------------+-------------------+--------------------+\n",
      "|        #covid|1376807677934854152|Talking to my fri...|\n",
      "|        #covid|1376807674843701256|Sufficient doses ...|\n",
      "|        #covid|1376807578898993152|Is Dubai open for...|\n",
      "|        #covid|1376807577879728128|Register now Econ...|\n",
      "|        #biden|1376807944138977280|Fears over potent...|\n",
      "|        #biden|1376806460772995072|court case agains...|\n",
      "|        #biden|1376806405261365248|Journalists conti...|\n",
      "|        #biden|1376806257445732352|Any tips on wind ...|\n",
      "|        #biden|1376805813377921026|GOLD STOCKS: Spot...|\n",
      "|    #inflation|1376806399930327042|Singapore‚Äôs core ...|\n",
      "|    #inflation|1376806224218320899|US Dollar or Keer...|\n",
      "|    #inflation|1376806050477830144|Re-#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà resum...|\n",
      "|    #inflation|1376805646742417413|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà: IndiaEs...|\n",
      "|    #inflation|1376803909038051332|@Pri_Kishore, Hea...|\n",
      "|    #inflation|1376807928225746945|The debate on #‚ñà‚ñà...|\n",
      "|      #vaccine|1376808262092402688|@SpokespersonCHN ...|\n",
      "|      #vaccine|1376808111416086529|Chinese President...|\n",
      "|#stopasianhate|1376808977057656835|@koreworldw We st...|\n",
      "|#stopasianhate|1376808974301986818|@tatavantaes We s...|\n",
      "|#stopasianhate|1376808974109048834|@cleeocean We sta...|\n",
      "+--------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1376807677934854152|Talking to my fri...|\n",
      "|#covid|1376807674843701256|Sufficient doses ...|\n",
      "+------+-------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2,truncate= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207993\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1376807677934854152|Talking to my fri...|\n",
      "+------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.tweet_id == 1376807677934854152).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1376807677934854152|Talking to my fri...|\n",
      "+------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.tweet_id == 1376807677934854152).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+--------------------+\n",
      "|summary|   label|            tweet_id|          tweet_text|\n",
      "+-------+--------+--------------------+--------------------+\n",
      "|  count|  207993|              207993|              207993|\n",
      "|   mean|    null|1.387666180356198...|                null|\n",
      "| stddev|    null|  6.1606223029364E15|                null|\n",
      "|    min|  #biden| 1376803909038051332|!   #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Pled...|\n",
      "|    max|#vaccine| 1398244775682248709|ü™° Thread produce...|\n",
      "+-------+--------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|tweet_text                                                                                                                                                                                                                                                                                                         |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Talking to my friend she said that you can get covid from someone newly vaccinated because they have been injected with the virus, I just have no words to counteract this bullshit , believe what you want to believe why don‚Äôt you üôã‚Äç‚ôÄÔ∏è üíâ #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                           |\n",
      "|Sufficient doses of the #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà-19 #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà are available to sustain the vaccination programme as it ramps up.\n",
      "\n",
      "Learn more about the #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà-19 #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà \n",
      "üëá\n",
      "https://t.co/Yzojc1f4bG\n",
      "\n",
      "@DrAliLea @roylepryor @gillylee @angelaosei @Natasha_odita @GMNurses @GPExcellenceGM @gpncare https://t.co/vbsBxwR0rX      |\n",
      "|Is Dubai open for tourists https://t.co/yKyhPYim3D via @YouTube #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñàAB #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                |\n",
      "|Register now Economic Policy Panel Meeting 15 April 5:00 pm 'Tackling the Inequality Effects of #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà - &amp; How to Pay For It' with @S_Stantcheva @Harvard @gabriel_zucman @UCBerkeley @NgaireWoods @RanaForoohar @CNN @FT @OUPEconomics @sciencespo @cepr_org https://t.co/bjc7tdhXTa https://t.co/yrkqap8h9h|\n",
      "|Fears over potential fourth surge rise as White House sends warning to Covid-weary Americans. | Analysis by @StCollinson. https://t.co/uaBDaaXVeM https://t.co/effhYL6aaH #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                        |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('tweet_text').show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+----------+\n",
      "|         label|COUNT|PERCENTAGE|\n",
      "+--------------+-----+----------+\n",
      "|        #covid|54391|     0.262|\n",
      "|      #vaccine|47681|     0.229|\n",
      "|        #china|45402|     0.218|\n",
      "|        #biden|31891|     0.153|\n",
      "|#stopasianhate|21501|     0.103|\n",
      "|    #inflation| 7127|     0.034|\n",
      "+--------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('table')\n",
    "sqlCtx.sql(\n",
    "    'SELECT label, COUNT(label) AS COUNT, ROUND(COUNT(label)/207993,3) AS PERCENTAGE       FROM table         GROUP BY label         order by COUNT desc'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+---------------+\n",
      "|count(DISTINCT tweet_id)|count(tweet_id)|\n",
      "+------------------------+---------------+\n",
      "|                  207993|         207993|\n",
      "+------------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('table')\n",
    "sqlCtx.sql(\n",
    "    'SELECT count( distinct tweet_id),  count(  tweet_id)      FROM table        '\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+--------------------+\n",
      "|         label|           tweet_id|          tweet_text|\n",
      "+--------------+-------------------+--------------------+\n",
      "|        #covid|1376807677934854152|talking to my fri...|\n",
      "|        #covid|1376807674843701256|sufficient doses ...|\n",
      "|        #covid|1376807578898993152|is dubai open for...|\n",
      "|        #covid|1376807577879728128|register now econ...|\n",
      "|        #biden|1376807944138977280|fears over potent...|\n",
      "|        #biden|1376806460772995072|court case agains...|\n",
      "|        #biden|1376806405261365248|journalists conti...|\n",
      "|        #biden|1376806257445732352|any tips on wind ...|\n",
      "|        #biden|1376805813377921026|gold stocks: spot...|\n",
      "|    #inflation|1376806399930327042|singapore‚Äôs core ...|\n",
      "|    #inflation|1376806224218320899|us dollar or keer...|\n",
      "|    #inflation|1376806050477830144|re-#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà resum...|\n",
      "|    #inflation|1376805646742417413|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà: indiaes...|\n",
      "|    #inflation|1376803909038051332|@pri_kishore, hea...|\n",
      "|    #inflation|1376807928225746945|the debate on #‚ñà‚ñà...|\n",
      "|      #vaccine|1376808262092402688|@spokespersonchn ...|\n",
      "|      #vaccine|1376808111416086529|chinese president...|\n",
      "|#stopasianhate|1376808977057656835|@koreworldw we st...|\n",
      "|#stopasianhate|1376808974301986818|@tatavantaes we s...|\n",
      "|#stopasianhate|1376808974109048834|@cleeocean we sta...|\n",
      "+--------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lowering letters\n",
    "\n",
    "\n",
    "df = df.withColumn(\"tweet_text\",f.lower(f.col(\"tweet_text\")))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## length of the strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|tweet_leng|\n",
      "+----------+\n",
      "|978       |\n",
      "|961       |\n",
      "|960       |\n",
      "+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = df.withColumn(\"tweet_leng\",f.length(f.col(\"tweet_text\")))\n",
    "temp.select('tweet_leng').sort(temp.tweet_leng.desc()).show(3, truncate=False) \n",
    "# minimum length is 13 \n",
    "# max length is  978       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|tweet_text   |\n",
      "+-------------+\n",
      "|stop #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|\n",
      "|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà done|\n",
      "|also #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|\n",
      "|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà scam|\n",
      "|also #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|\n",
      "|fuck #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|\n",
      "|fuck #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|\n",
      "|test #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|\n",
      "|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà test|\n",
      "|fuck #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|\n",
      "|fuck #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp.select('tweet_text').filter(temp.tweet_leng == 13).show(11, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|tweet_text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|@erezneumark @cocoroc83197272 @awadham75384405 @zammi @scripteladora @sabra_the @malekcomedy @p3ng1z @thezionist3 @michael__baskin @exposefakestine @marknew97599142 @jbarnathan @cynpapas @siobanvict @adhamsa70052369 @2bootz9 @wurzel260654 @void_deathwatch @matgoolys1 @realhasdaic @yaacovba @menelik61968474 @sonof_egypt @random2021n @dsdloveyou @lavbaaldevarim @gloryda17702388 @copia_copma1 @hebmacman @despinne @malkaavram @adhamsa38600622 @angelotstvil @dreyfusshawn @comrade_sebs @azzeus_ @zico20907906 @insertnickname7 @sexhaver5000 @arjar20 @walmartunion69 @antifatoast @teddysmom8 @reaihasdiac @negusabe @kalambish @pakeha56 @amirlein @awadhamedmoham2 this is exactly the result of #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà'sopport from #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà terrorists criminals murders liars &amp; corrupt regime in #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà this regime is a cancer and should wipe it out for the sake of health, safety, &amp; stability of #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñàians in #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà &amp; #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà east people. #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà devil https://t.co/8d51hh2xo2|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp.select('tweet_text').filter(temp.tweet_leng == 978).show(11, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean the sentences from punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label |tweet_id           |tweet_text                                                                                                                                                                                                                                                                                             |\n",
      "+------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|#covid|1376807677934854152|talking to my friend she said that you can get covid from someone newly vaccinated because they have been injected with the virus i just have no words to counteract this bullshit  believe what you want to believe why don‚Äôt you üôã‚Äç‚ôÄÔ∏è üíâ #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 |\n",
      "|#covid|1376807674843701256|sufficient doses of the #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà19 #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà are available to sustain the vaccination programme as it ramps up\n",
      "\n",
      "learn more about the #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà19 #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà \n",
      "üëá\n",
      "https://tco/yzojc1f4bg\n",
      "\n",
      "@dralilea @roylepryor @gillylee @angelaosei @natashaodita @gmnurses @gpexcellencegm @gpncare https://tco/vbsbxwr0rx|\n",
      "+------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lowering letters\n",
    "#import pyspark.sql.functions as f\n",
    "df = df.withColumn(\"tweet_text\",f.regexp_replace(\"tweet_text\", r',|\\.|&|$|%|\\\\|\\||-|_', ''))\n",
    "df.show(2, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781788474221/7/ch07lvl1sec63/removing-stop-words-from-the-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the most frequent word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec\n",
    "# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.Word2Vec.html\n",
    "# https://spark.apache.org/docs/latest/ml-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split into train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145524\n",
      "62469\n"
     ]
    }
   ],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], 1234) # 70% of train set\n",
    "print(train.count())\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline with word2vec\n",
    "## model logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hanhanwu/Hanhan-Spark-Python/blob/master/RandomForests.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "dataFrame = spark.createDataFrame([\n",
    "    (0, Vectors.dense([1.0, 0.5, -1.0]),),\n",
    "    (1, Vectors.dense([2.0, 1.0, 1.0]),),\n",
    "    (2, Vectors.dense([4.0, 10.0, 2.0]),)\n",
    "], [\"id\", \"features\"])\n",
    "\n",
    "# Normalize each Vector using $L^1$ norm.\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)\n",
    "l1NormData = normalizer.transform(dataFrame)\n",
    "print(\"Normalized using L^1 norm\")\n",
    "l1NormData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.\n",
    "stage_0 = StringIndexer(inputCol=\"label\", outputCol=\"label_encoded\")\n",
    "stage_1 = RegexTokenizer(inputCol= 'tweet_text' , outputCol= 'tokens', pattern= '\\\\W')\n",
    "stage_2 = StopWordsRemover(inputCol= 'tokens', outputCol= 'filtered_stop_words')\n",
    "word2Vec = Word2Vec(inputCol= 'filtered_stop_words', outputCol= 'vector', vectorSize= 500)\n",
    "modelLR = LogisticRegression(featuresCol=\"vector\", labelCol=\"label_encoded\", maxIter=10000, regParam=0.05, elasticNetParam=0.05)\n",
    "\n",
    "pipeline = Pipeline(stages=[stage_0,stage_1, stage_2, word2Vec, modelLR])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+-------------+--------------------+--------------------+----------+\n",
      "|           tweet_id| label|label_encoded|       rawPrediction|         probability|prediction|\n",
      "+-------------------+------+-------------+--------------------+--------------------+----------+\n",
      "|1376805813377921026|#biden|          3.0|[-0.7090734024493...|[0.03156344415520...|       2.0|\n",
      "|1376806257445732352|#biden|          3.0|[0.31908328049681...|[0.12084199037427...|       2.0|\n",
      "|1376807944138977280|#biden|          3.0|[0.36246240428153...|[0.23828668756625...|       3.0|\n",
      "|1377203682635350016|#biden|          3.0|[-0.2180711526915...|[0.09051680446793...|       3.0|\n",
      "|1377204875335979008|#biden|          3.0|[-0.5928024717694...|[0.07086371284188...|       2.0|\n",
      "+-------------------+------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(test)\n",
    "prediction.select('tweet_id','label', \"label_encoded\",\"rawPrediction\",\"probability\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.634619 \n",
      "Test Error = 0.365381 \n",
      "truPosit = 0.669881 \n",
      "falPosit = 0.16327 \n",
      "precisionByLabel = 0.597442 \n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_encoded\", predictionCol=\"prediction\") \n",
    "\n",
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName: \"accuracy\" })\n",
    "print(\"accuracy = %g \" % (accuracy))\n",
    "\n",
    "testError = evaluator.evaluate(prediction, {evaluator.metricName: \"accuracy\" })\n",
    "print(\"Test Error = %g \" % (1.0 - testError))\n",
    "\n",
    "truPosit = evaluator.evaluate(prediction, {evaluator.metricName: \"truePositiveRateByLabel\"})\n",
    "print(\"truPosit = %g \" % ( truPosit))\n",
    "\n",
    "\n",
    "falPosit = evaluator.evaluate(prediction, {evaluator.metricName: \"falsePositiveRateByLabel\"})\n",
    "print(\"falPosit = %g \" % ( falPosit))\n",
    "\n",
    "\n",
    "precisionByLabel = evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "print(\"precisionByLabel = %g \" % ( precisionByLabel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## roc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## archieved results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-340-e28a9c5d362f>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-340-e28a9c5d362f>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    10 000\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# accuracy 0.2595239700627065 \n",
    "# maxIter=1 000\n",
    "\n",
    "# accuracy 0.2595239700627065\n",
    "# maxIter=1 000\n",
    "\n",
    "# accuracy 0.25973035375608144\n",
    "# maxIter= 10 000\n",
    "\n",
    "#0.25973035375608144\n",
    "#10 000\n",
    "\n",
    "\n",
    "word2Vec = Word2Vec(inputCol= 'filtered_stop_words', outputCol= 'vector', vectorSize= 300)\n",
    "model_w2v = word2Vec.fit(stopwordsData)\n",
    "Accuracy = 0.5644635936340398\n",
    "modelLR = LogisticRegression(featuresCol=\"vector\", labelCol=\"label_encoded\", maxIter=100000, regParam=0.2, elasticNetParam=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stage 3: create a word vector \n",
    "word2Vec = Word2Vec(inputCol= 'filtered_stop_words', outputCol= 'vector', vectorSize= 500)\n",
    "model_w2v = word2Vec.fit(stopwordsData)\n",
    "# define stage 4: Logistic Regression Model\n",
    "modelLR = LogisticRegression(featuresCol=\"vector\", labelCol=\"label_encoded\", maxIter=100000, regParam=0.2, elasticNetParam=0.2)\n",
    "modelLR = modelLR.fit(train)\n",
    "Accuracy = 0.5716514114510322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stage 3: create a word vector of the size 100\n",
    "word2Vec = Word2Vec(inputCol= 'filtered_stop_words', outputCol= 'vector', vectorSize= 500)\n",
    "model_w2v = word2Vec.fit(stopwordsData)\n",
    "# define stage 4: Logistic Regression Model\n",
    "modelLR = LogisticRegression(featuresCol=\"vector\", labelCol=\"label_encoded\", maxIter=10000, regParam=0.1, elasticNetParam=0.1)\n",
    "modelLR = modelLR.fit(train)\n",
    "Accuracy = 0.6250240510156401\n",
    "totalIterations:248\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
